package org.apache.hadoop.hive.ql.udf.generic;

import java.util.ArrayList;

import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.hadoop.hive.common.type.HiveDecimal;
import org.apache.hadoop.hive.ql.exec.Description;
import org.apache.hadoop.hive.ql.exec.UDFArgumentTypeException;
import org.apache.hadoop.hive.ql.metadata.HiveException;
import org.apache.hadoop.hive.ql.parse.SemanticException;
import org.apache.hadoop.hive.ql.udf.generic.AbstractGenericUDAFResolver;
import org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator;
import org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator.AggregationBuffer;
import org.apache.hadoop.hive.ql.util.JavaDataModel;
import org.apache.hadoop.hive.serde2.io.DoubleWritable;
import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;
import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;
import org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector;
import org.apache.hadoop.hive.serde2.objectinspector.StructField;
import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;
import org.apache.hadoop.hive.serde2.objectinspector.primitive.DoubleObjectInspector;
import org.apache.hadoop.hive.serde2.objectinspector.primitive.HiveDecimalObjectInspector;
import org.apache.hadoop.hive.serde2.objectinspector.primitive.LongObjectInspector;
import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;
import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorUtils;
import org.apache.hadoop.hive.serde2.typeinfo.DecimalTypeInfo;
import org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo;
import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.util.StringUtils;

/**
 * GenericUDAFAverage.
 *
 */
@Description(name = "avg", value = "_FUNC_(x) - Returns the mean of a set of numbers")
public class GenericUDAFAverage extends AbstractGenericUDAFResolver {

	static final Log LOG = LogFactory.getLog(GenericUDAFAverage.class.getName());

	@Override
	public GenericUDAFEvaluator getEvaluator(TypeInfo[] parameters) throws SemanticException {
		if (parameters.length != 1) {
			throw new UDFArgumentTypeException(parameters.length - 1, "Exactly one argument is expected.");
		}

		if (parameters[0].getCategory() != ObjectInspector.Category.PRIMITIVE) {
			throw new UDFArgumentTypeException(0,
					"Only primitive type arguments are accepted but " + parameters[0].getTypeName() + " is passed.");
		}
		switch (((PrimitiveTypeInfo) parameters[0]).getPrimitiveCategory()) {
		case BYTE:
		case SHORT:
		case INT:
		case LONG:
		case FLOAT:
		case DOUBLE:
		case STRING:
		case VARCHAR:
		case CHAR:
		case TIMESTAMP:
			return new GenericUDAFAverageEvaluatorDouble();
		case DECIMAL:
			return new GenericUDAFAverageEvaluatorDecimal();
		case BOOLEAN:
		case DATE:
		default:
			throw new UDFArgumentTypeException(0, "Only numeric or string type arguments are accepted but "
					+ parameters[0].getTypeName() + " is passed.");
		}
	}

	public static class GenericUDAFAverageEvaluatorDouble extends AbstractGenericUDAFAverageEvaluator<Double> {

		@Override
		//重写doReset接口
		//调用reset时候在AbstractGenericUDAFAverageEvaluator(父类)中被调用
		public void doReset(AverageAggregationBuffer<Double> aggregation) throws HiveException {
			aggregation.count = 0;
			aggregation.sum = new Double(0);
		}

		@Override
		//得到求和的javaObjectInspector
		protected ObjectInspector getSumFieldJavaObjectInspector() {
			return PrimitiveObjectInspectorFactory.javaDoubleObjectInspector;
		}

		@Override
		//得到求和的WritableObjectInspector(for hadoop)
		protected ObjectInspector getSumFieldWritableObjectInspector() {
			return PrimitiveObjectInspectorFactory.writableDoubleObjectInspector;
		}

		@Override
		//重写doReset接口
		//调用Iterate时候在AbstractGenericUDAFAverageEvaluator(父类)中被调用
		protected void doIterate(AverageAggregationBuffer<Double> aggregation, PrimitiveObjectInspector oi,
				Object parameter) {
			//从oi中取出parameter对应的值
			double value = PrimitiveObjectInspectorUtils.getDouble(parameter, oi);
			aggregation.count++;
			aggregation.sum += value;

		}

		@Override
		//重写doMerge接口
		//调用Merge时候在AbstractGenericUDAFAverageEvaluator(父类)中被调用
		protected void doMerge(AverageAggregationBuffer<Double> aggregation, Long partialCount,ObjectInspector sumFieldOI, Object partialSum) {
			double value = ((DoubleObjectInspector) sumFieldOI).get(partialSum);
			aggregation.count += partialCount;
			aggregation.sum += value;
		}

		@Override
		//重写doTerminatePartial接口
		//调用TerminatePartial时候在AbstractGenericUDAFAverageEvaluator(父类)中被调用
		protected void doTerminatePartial(AverageAggregationBuffer<Double> aggregation) {
			if (partialResult[1] == null) {
				partialResult[1] = new DoubleWritable(0);
			}
			((LongWritable) partialResult[0]).set(aggregation.count);
			((DoubleWritable) partialResult[1]).set(aggregation.sum);
		}

		@Override
		//重写doTerminate接口
		//调用Terminate时候在AbstractGenericUDAFAverageEvaluator(父类)中被调用
		protected Object doTerminate(AverageAggregationBuffer<Double> aggregation) {
			if (aggregation.count == 0) {
				return null;
			} else {
				DoubleWritable result = new DoubleWritable(0);
				result.set(aggregation.sum / aggregation.count);
				return result;
			}
		}

		@Override
		public AggregationBuffer getNewAggregationBuffer() throws HiveException {
			AverageAggregationBuffer<Double> result = new AverageAggregationBuffer<Double>();
			reset(result);
			return result;
		}
	}

	public static class GenericUDAFAverageEvaluatorDecimal extends AbstractGenericUDAFAverageEvaluator<HiveDecimal> {

		@Override
		public void doReset(AverageAggregationBuffer<HiveDecimal> aggregation) throws HiveException {
			aggregation.count = 0;
			aggregation.sum = HiveDecimal.ZERO;
		}

		@Override
		protected ObjectInspector getSumFieldJavaObjectInspector() {
			DecimalTypeInfo typeInfo = deriveResultDecimalTypeInfo();
			return PrimitiveObjectInspectorFactory.getPrimitiveJavaObjectInspector(typeInfo);
		}

		@Override
		protected ObjectInspector getSumFieldWritableObjectInspector() {
			DecimalTypeInfo typeInfo = deriveResultDecimalTypeInfo();
			return PrimitiveObjectInspectorFactory.getPrimitiveWritableObjectInspector(typeInfo);
		}

		private DecimalTypeInfo deriveResultDecimalTypeInfo() {
			int prec = inputOI.precision();
			int scale = inputOI.scale();
			if (mode == Mode.FINAL || mode == Mode.COMPLETE) {
				int intPart = prec - scale;
				// The avg() result type has the same number of integer digits and 4 more
				// decimal digits.
				scale = Math.min(scale + 4, HiveDecimal.MAX_SCALE - intPart);
				return TypeInfoFactory.getDecimalTypeInfo(intPart + scale, scale);
			} else {
				// For intermediate sum field
				return GenericUDAFAverage.deriveSumFieldTypeInfo(prec, scale);
			}
		}

		@Override
		protected void doIterate(AverageAggregationBuffer<HiveDecimal> aggregation, PrimitiveObjectInspector oi,
				Object parameter) {
			HiveDecimal value = PrimitiveObjectInspectorUtils.getHiveDecimal(parameter, oi);
			aggregation.count++;
			if (aggregation.sum != null) {
				aggregation.sum = aggregation.sum.add(value);
			}
		}

		@Override
		protected void doMerge(AverageAggregationBuffer<HiveDecimal> aggregation, Long partialCount,
				ObjectInspector sumFieldOI, Object partialSum) {
			HiveDecimal value = ((HiveDecimalObjectInspector) sumFieldOI).getPrimitiveJavaObject(partialSum);
			if (value == null) {
				aggregation.sum = null;
			}
			aggregation.count += partialCount;
			if (aggregation.sum != null) {
				aggregation.sum = aggregation.sum.add(value);
			}
		}

		@Override
		protected void doTerminatePartial(AverageAggregationBuffer<HiveDecimal> aggregation) {
			if (partialResult[1] == null && aggregation.sum != null) {
				partialResult[1] = new HiveDecimalWritable(HiveDecimal.ZERO);
			}
			((LongWritable) partialResult[0]).set(aggregation.count);
			if (aggregation.sum != null) {
				((HiveDecimalWritable) partialResult[1]).set(aggregation.sum);
			} else {
				partialResult[1] = null;
			}
		}

		@Override
		protected Object doTerminate(AverageAggregationBuffer<HiveDecimal> aggregation) {
			if (aggregation.count == 0 || aggregation.sum == null) {
				return null;
			} else {
				HiveDecimalWritable result = new HiveDecimalWritable(HiveDecimal.ZERO);
				result.set(aggregation.sum.divide(HiveDecimal.create(aggregation.count)));
				return result;
			}
		}

		@Override
		public AggregationBuffer getNewAggregationBuffer() throws HiveException {
			AverageAggregationBuffer<HiveDecimal> result = new AverageAggregationBuffer<HiveDecimal>();
			reset(result);
			return result;
		}
	}

	private static class AverageAggregationBuffer<TYPE> implements AggregationBuffer {
		private long count;
		private TYPE sum;
	};

	@SuppressWarnings("unchecked")
	public static abstract class AbstractGenericUDAFAverageEvaluator<TYPE> extends GenericUDAFEvaluator {

		// For PARTIAL1 and COMPLETE
		protected transient PrimitiveObjectInspector inputOI;
		// For PARTIAL2 and FINAL
		private transient StructObjectInspector soi;
		private transient StructField countField;
		private transient StructField sumField;
		private LongObjectInspector countFieldOI;
		protected ObjectInspector sumFieldOI;
		// For PARTIAL1 and PARTIAL2
		protected transient Object[] partialResult;

		private boolean warned = false;

		protected abstract ObjectInspector getSumFieldJavaObjectInspector();

		protected abstract ObjectInspector getSumFieldWritableObjectInspector();

		protected abstract void doIterate(AverageAggregationBuffer<TYPE> aggregation, PrimitiveObjectInspector inputOI,
				Object parameter);

		protected abstract void doMerge(AverageAggregationBuffer<TYPE> aggregation, Long partialCount,
				ObjectInspector sumFieldOI, Object partialSum);

		protected abstract void doTerminatePartial(AverageAggregationBuffer<TYPE> aggregation);

		protected abstract Object doTerminate(AverageAggregationBuffer<TYPE> aggregation);

		protected abstract void doReset(AverageAggregationBuffer<TYPE> aggregation) throws HiveException;

		@Override
		public ObjectInspector init(Mode m, ObjectInspector[] parameters) throws HiveException {
			assert (parameters.length == 1);
			//mode=m
			super.init(m, parameters);

			// init input
			if (mode == Mode.PARTIAL1 || mode == Mode.COMPLETE) {//map的过程的时候只有输入的流就可以实现
				inputOI = (PrimitiveObjectInspector) parameters[0];
			} else {//reduce过程需要配置输出流和输入流 
				soi = (StructObjectInspector) parameters[0];//这个是map的结果流，就是下面的return ObjectInspectorFactory.getStandardStructObjectInspector(fname, foi);
				countField = soi.getStructFieldRef("count");//从map给的流中得到count(计数器)的域
				sumField = soi.getStructFieldRef("sum");//从map给的流中得到sum(计数器)的域
				countFieldOI = (LongObjectInspector) countField.getFieldObjectInspector();//从map给的流中得到count(计数器)的域中得到countFieldOI流
				sumFieldOI = sumField.getFieldObjectInspector();//从map给的流中得到sum(计数器)的域中得到sumFieldOI流
				inputOI = (PrimitiveObjectInspector) soi.getStructFieldRef("input").getFieldObjectInspector();
			}

			// init output
			if (mode == Mode.PARTIAL1 || mode == Mode.PARTIAL2) {//这两个模式是需要输出流的
				// The output of a partial aggregation is a struct containing
				// a "long" count and a "double" sum.
				ArrayList<ObjectInspector> foi = new ArrayList<ObjectInspector>();
				foi.add(PrimitiveObjectInspectorFactory.writableLongObjectInspector);
				foi.add(getSumFieldWritableObjectInspector());
				// We need to "remember" the input object inspector so that we need to know the
				// input type
				// in order to determine the sum field type (precision/scale) for Mode.PARTIAL2
				// and Mode.FINAL.
				foi.add(inputOI);
				ArrayList<String> fname = new ArrayList<String>();
				fname.add("count");
				fname.add("sum");
				fname.add("input");
				partialResult = new Object[2];
				partialResult[0] = new LongWritable(0);//0位置放的是count
				// index 1 set by child
				return ObjectInspectorFactory.getStandardStructObjectInspector(fname, foi);
			} else {
				//只有输入流
				return getSumFieldWritableObjectInspector();
			}
		}

		@AggregationType(estimable = true)
		static class AverageAgg extends AbstractAggregationBuffer {
			long count;
			double sum;

			@Override
			public int estimate() {
				return JavaDataModel.PRIMITIVES2 * 2;
			}
		};

		@Override
		public void reset(AggregationBuffer aggregation) throws HiveException {
			doReset((AverageAggregationBuffer<TYPE>) aggregation);
		}

		@Override
		public void iterate(AggregationBuffer aggregation, Object[] parameters) throws HiveException {
			assert (parameters.length == 1);
			Object parameter = parameters[0];
			if (parameter != null) {
				AverageAggregationBuffer<TYPE> averageAggregation = (AverageAggregationBuffer<TYPE>) aggregation;
				try {
					//要从inputOI中得到parameter的值
					doIterate(averageAggregation, inputOI, parameter);
				} catch (NumberFormatException e) {
					if (!warned) {
						warned = true;
						LOG.warn("Ignoring similar exceptions: " + StringUtils.stringifyException(e));
					}
				}
			}
		}

		@Override
		public Object terminatePartial(AggregationBuffer aggregation) throws HiveException {
			doTerminatePartial((AverageAggregationBuffer<TYPE>) aggregation);
			return partialResult;
		}

		@Override
		public void merge(AggregationBuffer aggregation, Object partial) throws HiveException {//这里的partial就是partialResult=Object[2]
			if (partial != null) {
				//countField = soi.getStructFieldRef("count");//从map给的流中得到count(计数器)的域
				//countFieldOI = (LongObjectInspector) countField.getFieldObjectInspector();//从map给的流中得到count(计数器)的域中得到countFieldOI流
				//doMerge(AverageAggregationBuffer<Double> aggregation, Long partialCount,ObjectInspector sumFieldOI, Object partialSum)
				//                                                                   (Object data, StructField fieldRef)
				doMerge((AverageAggregationBuffer<TYPE>) aggregation,countFieldOI.get(soi.getStructFieldData(partial, countField)), sumFieldOI,soi.getStructFieldData(partial, sumField));
			}
		}

		@Override
		public Object terminate(AggregationBuffer aggregation) throws HiveException {
			return doTerminate((AverageAggregationBuffer<TYPE>) aggregation);
		}
	}

	/**
	 * The intermediate sum field has 10 more integer digits with the same scale.
	 * This is exposed as static so that the vectorized AVG operator use the same
	 * logic
	 * 
	 * @param precision
	 * @param scale
	 * @return
	 */
	public static DecimalTypeInfo deriveSumFieldTypeInfo(int precision, int scale) {
		int intPart = precision - scale;
		intPart = Math.min(intPart + 10, HiveDecimal.MAX_PRECISION - scale);
		return TypeInfoFactory.getDecimalTypeInfo(intPart + scale, scale);
	}

}
